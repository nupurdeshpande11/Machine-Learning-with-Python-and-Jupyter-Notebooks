{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "website exists\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import urllib3     \n",
    "import unicodedata\n",
    "from bs4 import BeautifulSoup, SoupStrainer, Comment\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "url='http://openweathermap.org/'\n",
    "\n",
    "#Identify if website is valid\n",
    "http = urllib3.PoolManager()\n",
    "response = http.request('GET',url)\n",
    "if response.status == 200:\n",
    "    print (\"website exists\")\n",
    "else:\n",
    "    print (response.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//openweathermap.desk.com/\n",
      "//home.openweathermap.org/users/sign_up\n",
      "//home.openweathermap.org/users/sign_in\n",
      "#\n",
      "#\n",
      "None\n",
      "None\n",
      "/\n",
      "//home.openweathermap.org/users/sign_in\n",
      "//home.openweathermap.org/users/sign_up\n",
      "/city\n",
      "#\n",
      "/weathermap\n",
      "/weathermap?basemap=satellite&cities=false&layer=precipitation&lat=30&lon=-20&zoom=3\n",
      "//owm.io/beautiful_maps\n",
      "/api\n",
      "/price\n",
      "/examples\n",
      "/stations\n",
      "/widgets-constructor\n",
      "/news\n",
      "#\n",
      "/about\n",
      "/team\n",
      "/technology\n",
      "/city\n",
      "/weathermap\n",
      "/weathermap?cities=false\n",
      "http://owm.io/weathermap?basemap=satellite&layer=precipitation&cities=false\n",
      "http://openweathermap.org/examples#google1 \n",
      "http://openweathermap.org/examples\n",
      "/api\n",
      "/stations\n",
      "https://openweathermap.desk.com/customer/portal/emails/new\n",
      "../find?q=\n",
      "../weathermap\n",
      "../appid\n",
      "../api\n",
      "../current\n",
      "../forecast5\n",
      "../forecast16\n",
      "../history\n",
      "../history-bulk\n",
      "../for_agriculture\n",
      "../examples\n",
      "../api/weathermaps#examples\n",
      "../api/weathermaps#legend\n",
      "../api/weathermaps#library\n",
      "../price\n",
      "../price_subscribe\n",
      "https://openweathermap.desk.com/customer/portal/emails/new\n",
      "../stations\n",
      "/team\n",
      "/technology\n",
      "https://twitter.com/OpenWeatherMap\n",
      "https://www.facebook.com/groups/270748973021342\n",
      "https://plus.google.com/u/0/communities/101265402580965077532\n",
      "https://t.me/openweathermap\n",
      "https://github.com/search?q=openweathermap&ref=cmdform\n",
      "/about\n",
      "/privacy-policy\n",
      "/terms\n"
     ]
    }
   ],
   "source": [
    "#Finding all external links in the url\n",
    "soup=BeautifulSoup(response.data, \"lxml\")\n",
    "\n",
    "for link in soup.find_all('a'):\n",
    " print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully in C:\\<Users>\\Part2-Webscrapper_Nupur.xlsx\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import xlsxwriter\n",
    "def urlAnalyze(link):\n",
    "    urllink = link\n",
    "    result = \"\"\n",
    "    responseExcel = []\n",
    "    http = urllib3.PoolManager()\n",
    "    try:\n",
    "        if 'http' in urllink:\n",
    "            response = http.request('GET',link)\n",
    "            if response.status == 200:\n",
    "                 result = 'true'\n",
    "            else:\n",
    "                result = 'false'\n",
    "    except LocationValueError:\n",
    "            result = 'false'\n",
    "    \n",
    "    if not result:\n",
    "        result = 'false'\n",
    "    return result\n",
    "\n",
    "def excelDownload (excelOut):\n",
    "    file_save_path = 'Part2-Webscrapper_Nupur.xlsx'\n",
    "    workbook = xlsxwriter.Workbook(file_save_path)\n",
    "    worksheet = workbook.add_worksheet()\n",
    "\n",
    "    bold = workbook.add_format({'bold': 1})\n",
    "\n",
    "    worksheet.set_column(1, 1, 15)\n",
    "\n",
    "    worksheet.write('A1', 'URL', bold)\n",
    "    worksheet.write('B1', 'Textual Decription', bold)\n",
    "    worksheet.write('C1', 'Validity', bold)\n",
    "    worksheet.write('D1', 'Date time', bold)\n",
    "\n",
    "    row = 1\n",
    "    col = 0\n",
    "    for link, txt_desc, valid, date_time in (excelOut):\n",
    "        worksheet.write_string  (row, col,     link)\n",
    "        worksheet.write_string  (row, col + 1, txt_desc)\n",
    "        worksheet.write_string  (row, col + 2, valid)\n",
    "        worksheet.write_string  (row, col + 3, date_time)\n",
    "        row += 1\n",
    "    workbook.close()\n",
    "    print (\"File saved successfully in C:\\<Users>\\Part2-Webscrapper_Nupur.xlsx\")\n",
    "\n",
    "    \n",
    "excelOut = []\n",
    "for link in soup.find_all('a'):\n",
    "    if link.get_text() and link.get('href'):\n",
    "        response = urlAnalyze(link.get('href'))\n",
    "        excelOut.append([link.get('href'), link.get_text(), response,time.strftime(\"%c\")])\n",
    "         \n",
    "excelDownload(excelOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
